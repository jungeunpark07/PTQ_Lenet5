{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae42e62d-52d5-41e3-bb1a-0c7ba65c3ab7",
   "metadata": {},
   "source": [
    "# Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114df7ea-c3fa-47d7-bafc-9fe76df81d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd87a4ee-34c6-40c8-be95-b0bfa5f56e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from torchsummary import summary\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tq\n",
    "import os, time, math, copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_printoptions(precision=8, linewidth=50000)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936610fc-b826-4105-b8f5-aca27e1f55cd",
   "metadata": {},
   "source": [
    "# Print Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c80e2d-6adf-4fee-832d-ca9be8808d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK\t= '\\033[30m'\n",
    "RED\t\t= '\\033[31m'\n",
    "GREEN\t= '\\033[32m'\n",
    "YELLOW\t= '\\033[33m'\n",
    "BLUE\t= '\\033[34m'\n",
    "MAGENTA\t= '\\033[35m'\n",
    "CYAN\t= '\\033[36m'\n",
    "RESET\t= '\\033[0m'\n",
    "SEL\t\t= '\\033[7m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07042d8d-61a1-4895-b51c-ef1a9584334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class\tfxp:\n",
    "\tdef\t__init__(self, bIn, iBWF):\n",
    "\t\tself.iFullBW\t= len(bIn)\n",
    "\t\tself.iIntgBW\t= self.iFullBW - iBWF\n",
    "\t\tself.bSign\t\t= bIn[0]\n",
    "\t\tself.bIntg\t\t= bIn[:self.iIntgBW]\n",
    "\t\tself.bFrac\t\t= bIn[self.iIntgBW:]\n",
    "\t\tself.fFull\t\t= 0\n",
    "\t\ttry:\n",
    "\t\t\tfor idx, bit in enumerate(bIn):\n",
    "\t\t\t\tif\tidx == 0:\n",
    "\t\t\t\t\tself.fFull = self.fFull + int(bit,2) * -pow(2, self.iIntgBW - 1)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.fFull = self.fFull + int(bit,2) * pow(2, self.iIntgBW - 1 - idx)\n",
    "\t\texcept:\n",
    "\t\t\tprint(bIn)\n",
    "\t\tself.dispFull\t= RED + self.bIntg + BLUE + self.bFrac + RESET\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a5be79-0b57-4d5d-9229-dcfe6900e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class\tflp2fix:\n",
    "\tdef\t__init__(self, fIn, iBW, iBWF):\n",
    "\t\tself.fMin\t\t= - 2 ** (iBW - iBWF - 1)\n",
    "\t\tself.fMax\t\t= (2 ** (iBW-1) - 1) * (2 ** -iBWF)\n",
    "\t\tself.fResol\t\t= 2 ** -iBWF\n",
    "\t\tif fIn < self.fMin or fIn > self.fMax:\n",
    "\t\t\tprint(f'({fIn}): Out of input range ({self.fMax}/{self.fMin}) during flp -> fix converting ')\n",
    "\t\tself.iBW\t\t= iBW\n",
    "\t\tself.iBWI\t\t= iBW - iBWF\n",
    "\t\tself.iBWF\t\t= iBWF\n",
    "\n",
    "\t\tself.iFLP2INT\t= abs(int(fIn * 2 ** iBWF))\n",
    "\t\tif fIn < 0:\n",
    "\t\t\tself.iFLP2INT = 2 ** (iBW-1) - self.iFLP2INT\n",
    "\n",
    "\t\tif fIn >= 0:\n",
    "\t\t\tself.bFull = bin(self.iFLP2INT)[2:].rjust(iBW, '0')\n",
    "\t\telse:\n",
    "\t\t\tself.bFull = '1'+bin(self.iFLP2INT)[2:].rjust(iBW-1, '0')\n",
    "\t\t\tif len(self.bFull) > iBW:\n",
    "\t\t\t\tself.bFull = '0' * iBW\n",
    "\n",
    "\t\tself.cssFxp\t\t= fxp(self.bFull, self.iBWF)\n",
    "\t\tself.bSign\t\t= self.cssFxp.bSign\n",
    "\t\tself.bIntg\t\t= self.cssFxp.bIntg\n",
    "\t\tself.bFrac\t\t= self.cssFxp.bFrac\n",
    "\t\tself.fFull\t\t= self.cssFxp.fFull\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75346b45-fad2-4643-a086-9f79c75048ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def\tflp2fixTensor(fIn, iBW, iBWF):\n",
    "\tfMin = - 2 ** (iBW - iBWF - 1)\n",
    "\tfMax = (2 ** (iBW-1) - 1) * (2 ** -iBWF)\n",
    "\tfList = []\n",
    "\tfor aTensor in fIn.view(-1):\n",
    "\t\tfList.append(flp2fix(aTensor, iBW, iBWF).fFull)\n",
    "\treturn torch.tensor(fList).view(fIn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fd276c-3039-4782-b9cc-3a025e5f2e08",
   "metadata": {},
   "source": [
    "# User Define Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "550c26cd-69ef-492b-9516-3631b6507c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '~/dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81da7c0-fc83-4be2-8e6d-44c0c034bc40",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644a1959-2599-463e-990f-c4266e73ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch for MNIST dataset')\n",
    "parser.add_argument('--device', type=str, default='cpu', help='Device')\n",
    "parser.add_argument('--shuffle', action='store_true', default=False, help='enables data shuffle')\n",
    "parser.add_argument('--dataset', type=str, default='mnist', help='training dataset')\n",
    "parser.add_argument('--data_path', type=str, default=data_path, help='path to MNIST')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=10, help='number of epochs to train')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='optimizer')\n",
    "parser.add_argument('--loss_func', type=str, default='cel', help='optimizer')\n",
    "parser.add_argument('--quant_opt', type=str, default='asym', help='Type of Quantization')\n",
    "parser.add_argument('--full_bits', type=int, default=16, help='Number of Quantization Bits')\n",
    "parser.add_argument('--frac_bits', type=int, default=8, help='Number of Quantization Bits')\n",
    "parser.add_argument('--pretrained', type=bool, default=True, help='Pretrained Model')\n",
    "parser.add_argument('--act_quant', type=bool, default=False, help='Activation Quantization')\n",
    "parser.add_argument('--disp', type=bool, default=False, help='Display Model Information')\n",
    "\n",
    "args = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38083626-e399-49d1-8528-7ad07d2f57e5",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d593f93-d5ae-42f8-931e-4b6ab0889bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.device == 'cuda' else {}\n",
    "transforms = transforms.Compose([transforms.Resize((32,32)),transforms.ToTensor()])\n",
    "if args.dataset == 'mnist':\n",
    "\ttrain_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset=datasets.MNIST(\n",
    "\t\t\troot=args.data_path,\n",
    "\t\t\ttrain=True,\n",
    "\t\t\tdownload=True,\n",
    "\t\t\ttransform=transforms\n",
    "\t\t),\n",
    "\t\tbatch_size=args.batch_size,\n",
    "\t\tshuffle=args.shuffle,\n",
    "\t\t**kwargs\n",
    "\t)\n",
    "\n",
    "\ttest_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset=datasets.MNIST(\n",
    "\t\t\troot=args.data_path,\n",
    "\t\t\ttrain=False,\n",
    "\t\t\tdownload=True,\n",
    "\t\t\ttransform=transforms\n",
    "\t\t),\n",
    "\t\tbatch_size=args.batch_size,\n",
    "\t\tshuffle=args.shuffle,\n",
    "\t\t**kwargs\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac15596-d02e-4dfa-aed6-12d0af91c487",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee464dbd-aac4-4d82-8787-270f8cd3ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenet5(nn.Module):\n",
    "    def __init__(self): #layer sequential define\n",
    "        super(Lenet5, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5*5 square convolution\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.Conv2d1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5, stride = 1)\n",
    "        self.Conv2d2 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = 5, stride = 1)\n",
    "        self.Conv2d3 = nn.Conv2d(in_channels = 16, out_channels = 120, kernel_size = 5, stride = 1)\n",
    "        self.AvgPool2d = nn.AvgPool2d(kernel_size = 2)\n",
    "        self.Tanh = nn.Tanh()\n",
    "        self.Linear1 = nn.Linear(120, 84)\n",
    "        self.Linear2 = nn.Linear(84, 10)\n",
    "    def forward(self, x) :\n",
    "        x = self.Conv2d1(x)\n",
    "        x = self.Tanh(x)\n",
    "        x = self.AvgPool2d(x)\n",
    "        x = self.Conv2d2(x)\n",
    "        x = self.Tanh(x)\n",
    "        x = self.AvgPool2d(x)\n",
    "        x = self.Conv2d3(x)\n",
    "        x = self.Tanh(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.Linear1(x)\n",
    "        x = self.Tanh(x)\n",
    "        x = self.Linear2(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87b94f73-bd08-4b09-937c-b0788fba1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genOptimizer(model, args):\n",
    "\tif args.optimizer == 'sgd':\n",
    "\t\toptimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "\tif args.optimizer == 'adam':\n",
    "\t\toptimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\treturn optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24f3af82-03a9-4268-a864-87e3afaee89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genLossFunc(args):\n",
    "\tif args.loss_func == 'cel':\n",
    "\t\tloss_func = nn.CrossEntropyLoss()\n",
    "\treturn loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fb2e20e-9352-4066-8127-1a4118f076d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, epoch, args):\n",
    "    model.train()\n",
    "    loss_func = genLossFunc(args)\n",
    "    optimizer = genOptimizer(model, args)\n",
    "    max_batch_index = int(np.floor(len(train_loader.dataset)/args.batch_size)) #batch 번호 ..?\n",
    "    running_loss,correct = 0, 0\n",
    "    \n",
    "    for batch_index, (image, label) in enumerate(tq(train_loader, desc='Train', leave=False)):\n",
    "        image, label = image.to(args.device), label.to(args.device)\n",
    "        pred = model(image) #pred = model\n",
    "        loss = loss_func(pred, label) # model 이용해서 loss 구함)\n",
    "        running_loss += loss.item()#*image.size(0)\n",
    "        correct += (pred.argmax(1) == label).type(torch.int).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    final_loss = running_loss/len(train_loader.dataset)\n",
    "    correct_rate = 100 * correct / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1:<3d}: Avg. Loss: {final_loss:.4f}', end = '\\t')\n",
    "    print(f'Accuracy: {correct}/{len(train_loader.dataset)} ({correct_rate:>.1f}%)')\n",
    "    \n",
    "    return final_loss,correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd446a25-819f-4b37-989d-50a0353f6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, args):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_func = genLossFunc(args)\n",
    "        loss, correct = 0, 0\n",
    "# for batch_index, (image, label) in enumerate(tq(test_loader, desc='Test', leave=False)):\n",
    "        for batch_index, (image, label) in enumerate(test_loader):\n",
    "            image, label = image.to(args.device), label.to(args.device)\n",
    "            pred = model(image)\n",
    "            loss += loss_func(pred, label).item()#*image.size(0)\n",
    "            correct += (pred.argmax(1) == label).type(torch.int).sum().item()\n",
    "    loss /= len(test_loader.dataset)\n",
    "    correct_rate = 100 * correct / len(test_loader.dataset)\n",
    "    print(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%)')\n",
    "    return loss,correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c653a9bd-781a-47a9-bdcd-32f43bd1f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model):\n",
    "    train_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    eval_loss_hist = []\n",
    "    eval_acc_hist = []\n",
    "    for epoch in range(args.epochs):\n",
    "        train_loss,train_acc = train(train_loader, model, epoch, args)\n",
    "        eval_loss,eval_acc = test(test_loader, model, args)\n",
    "        train_loss_hist.append(train_loss)\n",
    "        eval_loss_hist.append(eval_loss)\n",
    "        train_acc_hist.append(train_acc)\n",
    "        eval_acc_hist.append(eval_acc)\n",
    "    print(\"Done!\")\n",
    "    return model,train_loss_hist,train_acc_hist,eval_loss_hist,eval_acc_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "485b1021-2707-4973-9c61-2a0273e71051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  : Avg. Loss: 0.0050\tAccuracy: 54373/60000 (90.6%)\n",
      "Accuracy: 9576/10000 (95.8%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2  : Avg. Loss: 0.0017\tAccuracy: 57974/60000 (96.6%)\n",
      "Accuracy: 9722/10000 (97.2%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3  : Avg. Loss: 0.0011\tAccuracy: 58746/60000 (97.9%)\n",
      "Accuracy: 9755/10000 (97.5%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4  : Avg. Loss: 0.0008\tAccuracy: 59114/60000 (98.5%)\n",
      "Accuracy: 9758/10000 (97.6%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5  : Avg. Loss: 0.0006\tAccuracy: 59344/60000 (98.9%)\n",
      "Accuracy: 9796/10000 (98.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6  : Avg. Loss: 0.0004\tAccuracy: 59523/60000 (99.2%)\n",
      "Accuracy: 9793/10000 (97.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7  : Avg. Loss: 0.0004\tAccuracy: 59594/60000 (99.3%)\n",
      "Accuracy: 9823/10000 (98.2%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8  : Avg. Loss: 0.0003\tAccuracy: 59623/60000 (99.4%)\n",
      "Accuracy: 9808/10000 (98.1%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9  : Avg. Loss: 0.0003\tAccuracy: 59674/60000 (99.5%)\n",
      "Accuracy: 9828/10000 (98.3%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : Avg. Loss: 0.0002\tAccuracy: 59739/60000 (99.6%)\n",
      "Accuracy: 9846/10000 (98.5%)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model,train_loss_hist,train_acc_hist,eval_loss_hist,eval_acc_hist = main(Lenet5().to(args.device))\n",
    "torch.save(model.state_dict(), 'PTQ.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "350ed278-1280-4b87-9c3e-df22702ae861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenet5(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (Conv2d1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (Conv2d2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (Conv2d3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (AvgPool2d): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (Tanh): Tanh()\n",
      "  (Linear1): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (Linear2): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26f59dbb-5579-4196-bc32-c579a258bdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "              Tanh-2            [-1, 6, 28, 28]               0\n",
      "         AvgPool2d-3            [-1, 6, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
      "              Tanh-5           [-1, 16, 10, 10]               0\n",
      "         AvgPool2d-6             [-1, 16, 5, 5]               0\n",
      "            Conv2d-7            [-1, 120, 1, 1]          48,120\n",
      "              Tanh-8            [-1, 120, 1, 1]               0\n",
      "            Linear-9                   [-1, 84]          10,164\n",
      "             Tanh-10                   [-1, 84]               0\n",
      "           Linear-11                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_size=(1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a012bf2a-6e27-4f18-9060-e95acc65299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2fix(model, args):\n",
    "\tfor name, _ in model.named_parameters():\n",
    "\t\texec(f'model.{name}.data = flp2fixTensor(model.{name}.data, {args.full_bits}, {args.frac_bits})')\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b2381db-f666-42a7-a1c5-14783fd70c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantFixForward(model, x, args):\n",
    "    cmodel = copy.deepcopy(model).to(args.device)\n",
    "    with torch.no_grad():\n",
    "        act0 = cmodel.AvgPool2d(cmodel.Tanh(cmodel.Conv2d1(x))) #activation\n",
    "        act0 = flp2fixTensor(act0, args.full_bits, args.frac_bits)\n",
    "\n",
    "        act1 = cmodel.AvgPool2d(cmodel.Tanh(cmodel.Conv2d2(act0)))\n",
    "        act1 = flp2fixTensor(act1, args.full_bits, args.frac_bits)\n",
    "\n",
    "        act2 = cmodel.Tanh(cmodel.Conv2d3(act1))\n",
    "        act2 = flp2fixTensor(act2, args.full_bits, args.frac_bits)\n",
    "\n",
    "        act3 = cmodel.flatten(act2)\n",
    "        act3 = flp2fixTensor(act3, args.full_bits, args.frac_bits)\n",
    "        \n",
    "        act4 = cmodel.Tanh(cmodel.Linear1(act3))\n",
    "        act4 = flp2fixTensor(act4, args.full_bits, args.frac_bits)\n",
    "        \n",
    "        act5 = cmodel.Linear2(act4)\n",
    "        act5 = flp2fixTensor(act5, args.full_bits, args.frac_bits)\n",
    "\n",
    "    return cmodel, act0, act1, act2, act3, act4, act5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6ce915d-0d0f-47b9-9773-8083124152d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQuant(model, test_loader,args):\n",
    "    qmodel = copy.deepcopy(model).to(args.device)\n",
    "    qmodel = model2fix(qmodel, args)\n",
    "    qmodel.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_func = genLossFunc(args)\n",
    "        loss, correct = 0, 0\n",
    "        for batch_index, (image, label) in enumerate(tq(test_loader,desc='Train', leave=False)):\n",
    "            image, label = image.to(args.device), label.to(args.device)\n",
    "            qmodel, act0, act1, act2, act3, act4, act5  = quantFixForward(qmodel, image, args)\n",
    "            y = act5\n",
    "            loss += loss_func(y, label).item()#*image.size(0)\n",
    "            correct += (y.argmax(1) == label).type(torch.int).sum().item()\n",
    "    correct_rate = 100 * correct / len(test_loader.dataset)\n",
    "    print(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%) Loss: {loss/len(test_loader.dataset):.2f}')\n",
    "    return qmodel, act0, act1, act2, act3, act4, act5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52290d52-8e05-4362-a162-64e63799035c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9846/10000 (98.5%) Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "qmodel, act0, act1, act2, act3, act4, act5= testQuant(model,test_loader,args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e6f74-e29b-4d97-a701-ea6e289a4aa1",
   "metadata": {},
   "source": [
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b1c2491-3a6f-44ad-a6a9-7e37014969d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"eval-loss\")\n",
    "\n",
    "plt.plot(range(1,args.epochs+1),train_loss_hist,label=\"train\")\n",
    "plt.plot(range(1,args.epochs+1),eval_loss_hist,label=\"eval\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa65192b-847b-40ed-94e9-4d7892b40a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"eval-Accuracy\")\n",
    "\n",
    "plt.plot(range(1,len(test_loader)),acc_hist,label=\"eval\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15f25f03-f4eb-4806-8379-a746aa340653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.plot(range(1,args.epochs+1),train_acc_hist,label=\"train\")\n",
    "plt.plot(range(1,args.epochs+1),eval_acc_hist,label=\"eval\")\n",
    "plt.ylabel(\"accruacy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0fa2c9-4630-4735-a388-f455d304abb3",
   "metadata": {},
   "source": [
    "# GenVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e61c86f3-ff4c-4912-8685-a439bbe33a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractParams(model, args):\n",
    "    for key in model.state_dict().keys():\n",
    "        layer_name = key.split('.')[0]\n",
    "        param_type = 'w' if 'weight' in key else 'b'\n",
    "        for idx, params in enumerate(eval(f'qmodel.{key}.data')):\n",
    "            with open(f'mif/{layer_name}_{param_type}_{idx}.mif', 'w') as fh:\n",
    "                if param_type == 'w':\n",
    "                    if params.dim() == 1 :\n",
    "                        #print(f'param dim is {params.dim()}')\n",
    "                        for idx, param in enumerate(params):\n",
    "                            bin_param = flp2fix(param, args.full_bits, args.frac_bits).bFull\n",
    "                            fh.write(bin_param + ('\\n','')[idx == len(params)-1])\n",
    "                    elif params.dim() == 3 :\n",
    "                        #print(f'param dim is {params.dim()}')\n",
    "                        for idx, dim1 in enumerate(params):\n",
    "                            for idx, dim2 in enumerate(dim1):\n",
    "                                for idx, param in enumerate(dim2) :\n",
    "                                    bin_param = flp2fix(param, args.full_bits, args.frac_bits).bFull\n",
    "                                    fh.write(bin_param + ('\\n','')[idx == len(params)-1])\n",
    "                else:\n",
    "                    bin_param = flp2fix(params, args.full_bits, args.frac_bits).bFull\n",
    "                    fh.write(bin_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c8a31dc-7015-4e44-9cd8-be2fd624a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genInputVector(test_loader, args):\n",
    "    out_path = './vec'\n",
    "    os.system(f'rm -rf {out_path};mkdir -p {out_path}')\n",
    "    with open(f'{out_path}/labels.vec', 'w') as fh_labels:\n",
    "        with open(f'{out_path}/images.vec', 'w') as fh_images:\n",
    "            for batch_index, (images, labels) in enumerate(test_loader):\n",
    "                for (image, label) in zip(images, labels):\n",
    "                    bin_label = flp2fix(label, args.full_bits, 0).bFull\n",
    "                    fh_labels.write(bin_label+'\\n')\n",
    "                    for pixel in image.view(-1):\n",
    "                        bin_pixel = flp2fix(pixel, args.full_bits, args.frac_bits).bFull\n",
    "                        fh_images.write(bin_pixel+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef70461-d364-4a85-92cd-0c39f0675132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not args.pretrained:\n",
    "extractParams(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d9791cf-47df-42eb-bcfd-f1e235598ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "genInputVector(test_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fede9d53-d71e-47dd-9440-c62d6c83b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(\troot=args.data_path,\n",
    "\t\t\t\t\t\t\ttrain=False,\n",
    "\t\t\t\t\t\t\tdownload=True,\n",
    "\t\t\t\t\t\t\ttransform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "607e2d07-f8ca-4820-b046-3781c9062383",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_index, (image, label) in enumerate(test_loader):\n",
    "           image, label = image.to(args.device), label.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87d71b4b-f97e-44af-b8cb-051ec5b1ee81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99e545a3-584f-4dc7-b297-fbcbaa6641d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 32, 32])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b1dbbf8-f3fc-4da4-83bc-86f7543101be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fe6e19a-2b4c-4cac-8ea9-763de12e85d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 32, 32])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_input = image\n",
    "a_input.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee43b4ec-c7af-48cf-8d1c-4c03a14f0949",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afdc0c-7bb9-42f4-a23b-e0faf6cce086",
   "metadata": {},
   "source": [
    "### conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4569ce2a-873f-4c72-af87-509498c7c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(X, filters,bias, stride=1, pad=0):\n",
    "    n, c, h, w = X.shape # 1, 1, 32, 32\n",
    "    n_f, _, filter_h, filter_w = filters.shape\n",
    "    \n",
    "    out_h = (h+2*pad-filter_h)//stride + 1\n",
    "    out_w = (w+2*pad-filter_w)//stride + 1\n",
    "    # add padding to height and width.\n",
    "    in_X = F.pad(X,(0,0,0,0,pad,pad,pad,pad),\"constant\", 0)\n",
    "    out  = torch.zeros((n, n_f, out_h, out_w))\n",
    "    \n",
    "    for i in range(n): # for each image.\n",
    "        for c in range(n_f): # for each channel.\n",
    "            for h in range(out_h): # slide the filter vertically.\n",
    "                h_start = h * stride\n",
    "                h_end = h_start + filter_h\n",
    "                for w in range(out_w): # slide the filter horizontally.\n",
    "                    w_start = w * stride\n",
    "                    w_end = w_start + filter_w\n",
    "                    # Element-wise multiplication.\n",
    "                    out[i, c, h, w] = torch.sum(in_X[i,:,h_start:h_end,w_start:w_end]*filters[c])+bias[c]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d097de5-3122-4451-a29e-9ecd2b8e30eb",
   "metadata": {},
   "source": [
    "### tanh_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ee8d591-bbf5-4fcf-b206-bb8308e84983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_4D(X):\n",
    "    n, c, h, w = X.shape\n",
    "    \n",
    "    out = torch.zeros(n,c,h,w)\n",
    "    \n",
    "    for i in range(n): #for each image\n",
    "        for ch in range(c) : #for each channel\n",
    "            for o_h in range(h) : #for each height\n",
    "                for o_w in range(w) : #for each width\n",
    "                    x = X[i, ch, o_h, o_w]\n",
    "                    out[i, ch, o_h, o_w] = (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634285a-385c-4adc-b16d-48390b197cfd",
   "metadata": {},
   "source": [
    "### tanh_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fef2a00e-c5ad-426d-b421-dbb892fec801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_2D(X):\n",
    "    n, c = X.shape\n",
    "    \n",
    "    out = torch.zeros(n,c)\n",
    "    \n",
    "    for i in range(n): #for each image\n",
    "        for ch in range(c) : #for each channel\n",
    "                    x = X[i, ch]\n",
    "                    out[i, ch] = (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b514de-2220-4e48-8c38-7eee5d2eba6f",
   "metadata": {},
   "source": [
    "### avgpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a4628c8-42b1-4dcb-838d-20ed940f4307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgpool2d(X,kernel_size,stride,pad=0):\n",
    "    n, c, h, w = X.shape\n",
    "    ker_w, ker_h = kernel_size\n",
    "    \n",
    "    out_h = (h + 2*pad - ker_h)//stride + 1\n",
    "    out_w = (w + 2*pad - ker_w)//stride + 1\n",
    "    \n",
    "    out = torch.zeros(n,c,out_h,out_w)\n",
    "    for i in range(n) : #for each image\n",
    "        for ch in range(c) : #for each channel \n",
    "             for h in range(out_h) :\n",
    "                    h_start = h * stride\n",
    "                    h_end = h_start + ker_w\n",
    "                    for w in range(out_w):\n",
    "                        w_start = w * stride\n",
    "                        w_end = w_start + ker_w\n",
    "                        #element average\n",
    "                        out[i, ch, h, w] = torch.mean(X[i,ch,h_start:h_end,w_start:w_end])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f5e21-3675-4a78-9f94-4fbf4e1013a3",
   "metadata": {},
   "source": [
    "### linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f176c-8735-4dcb-a763-6e685d280851",
   "metadata": {},
   "source": [
    "## checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fa2d71b-b6d4-466e-b840-a598f7a57742",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters1 = qmodel.Conv2d1.weight\n",
    "filters2 = qmodel.Conv2d2.weight\n",
    "filters3 = qmodel.Conv2d3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ecbe49f-47f5-44d8-a408-df727d92c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias1 = qmodel.Conv2d1.bias\n",
    "bias2 = qmodel.Conv2d2.bias\n",
    "bias3 = qmodel.Conv2d3.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84792791-321a-4fc9-931e-59a8d156c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_filter1 = qmodel.Linear1.weight\n",
    "linear_filter2 = qmodel.Linear2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f048caa-5905-4324-9d06-f8056b5806c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_bias1 = qmodel.Linear1.bias\n",
    "linear_bias2 = qmodel.Linear2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea6a0c8e-c3a2-430a-8311-d18c1877101c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84, 120])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_filter1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87dd94e7-f94e-4821-b7e7-a54144b5161b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 84])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_filter2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e07e1-d32a-49cf-9c7d-a65d4e66c61e",
   "metadata": {},
   "source": [
    "### act0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd151a5c-362d-4b25-8af9-0fe4d1ec9db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1 = conv(a_input,filters1,bias1,stride=1,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ceb262ca-a1f5-4539-b0dc-e5362b34b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_tanh1 = tanh_4D(layer_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5aca4a62-febd-4d03-b1d3-2c6db27fc94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_avgpool1 = avgpool2d(layer_tanh1,(2,2),2,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9274cd8-39f2-46e4-bb16-0d8abc208992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 14, 14])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_avgpool1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84b4e9e4-b3ed-42b3-8775-bfd6cadbcc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 14, 14])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa6f87ac-43ba-48e0-8e76-077b7743b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different value is : 0/18816\n"
     ]
    }
   ],
   "source": [
    "fix_act0 = torch.zeros(16,6,14,14)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(6) :\n",
    "        for c in range(14) :\n",
    "            for d in range(14) :\n",
    "                fix_act0[a][b][c][d] = flp2fix(layer_avgpool1[a][b][c][d],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act0[a][b][c][d],act0[a][b][c][d])==False):\n",
    "                    num += 1\n",
    "                #bin_conv1[a][b][c][d] = flp2fix(fix_conv1[a][b][c][d],args.full_bits,args.frac_bits).bFull\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b48be63e-b475-43a3-96c8-1b47ab42a723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(fix_act0,act0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19a199-0b9a-488d-8b00-97e49ed5729f",
   "metadata": {},
   "source": [
    "### act1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b97ec681-83b9-4585-a937-862ae90a6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv2 = conv(fix_act0,filters2,bias2,stride=1,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a707f846-356f-4d1d-82b2-65b877373350",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_tanh2 = tanh_4D(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "caeaa0b5-8da9-44dc-a72d-fdd40a2176e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_avgpool2 = avgpool2d(layer_tanh2,(2,2),2,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca2fdbc4-b15c-4002-8175-0a8693ee5857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 5, 5])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_avgpool2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "542f6201-c8c4-44ea-be0a-ab52be8a1e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 5, 5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41996925-65cc-4bf8-93ce-f08c57b3ca9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-0.99609375\n",
      "1.0\n",
      "0.99609375\n",
      "number of different value is : 2/6400\n"
     ]
    }
   ],
   "source": [
    "fix_act1 = torch.zeros(16,16,5,5)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(16) :\n",
    "        for c in range(5) :\n",
    "            for d in range(5) :\n",
    "                fix_act1[a][b][c][d] = flp2fix(layer_avgpool2[a][b][c][d],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act1[a][b][c][d],act1[a][b][c][d])==False):\n",
    "                    num += 1\n",
    "                    print(fix_act1[a][b][c][d].item())\n",
    "                    print(act1[a][b][c][d].item())\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dfb65f3d-5088-4223-816f-9da415725f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(fix_act1,act1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a9f3cd71-8a41-49ba-846b-d1755d7cabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_layer_conv2 = qmodel.Conv2d2(fix_act0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a1ef531d-5010-42d8-b370-574977814e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(layer_conv2,qmodel_layer_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a0244-c2cf-41a4-80b4-cb85c81b21b2",
   "metadata": {},
   "source": [
    "tanh 에서 에러 발생하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b037533d-31a6-444a-9523-135d9709b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_layer_tanh2 = qmodel.Tanh(qmodel_layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "72df75c8-ba80-44fa-bffd-b513ab78ea94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(layer_tanh2,qmodel_layer_tanh2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9cc7bd2c-c64b-45b1-af66-12583c1d742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different value is : 15192/25600\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(16) :\n",
    "        for c in range(10) :\n",
    "            for d in range(10) :\n",
    "                if (torch.equal(layer_tanh2[a][b][c][d],qmodel_layer_tanh2[a][b][c][d])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9fa28b7-1dd1-4c5b-91af-a54f2e9ffbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_layer_avgpool2 = qmodel.AvgPool2d(qmodel_layer_tanh2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2a298fd-76ea-4195-9cb3-48c9dd63245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_fix_act1 = torch.zeros(16,16,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51655bfd-fdca-4724-b088-713dd50f970d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different value is : 2/6400\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(16) :\n",
    "        for c in range(5) :\n",
    "            for d in range(5) :\n",
    "                qmodel_fix_act1[a][b][c][d] = flp2fix(qmodel_layer_avgpool2[a][b][c][d],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act1[a][b][c][d],qmodel_fix_act1[a][b][c][d])==False):\n",
    "                    num += 1                \n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad94aef8-9ecd-4cc3-996e-b03fba24bf34",
   "metadata": {},
   "source": [
    "### act2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7882e74-d68c-424b-b5d0-2e9e5533f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv3 = conv(fix_act1,filters3,bias3,stride=1,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8c7b56d-c09e-4235-a6bb-3e18b05e09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_tanh1 = tanh_4D(layer_conv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8efe4f6-0613-4e85-9011-4902eac029a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 120, 1, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_tanh1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "358f7e44-72d7-4d10-9258-28ceee56962f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 120, 1, 1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecd8cdd0-94d1-456a-8467-2dd41cb3a29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different value is : 47/1920\n"
     ]
    }
   ],
   "source": [
    "fix_act2 = torch.zeros(16,120,1,1)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(120) :\n",
    "        for c in range(1) :\n",
    "            for d in range(1) :\n",
    "                fix_act2[a][b][c][d] = flp2fix(layer_tanh1[a][b][c][d],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act2[a][b][c][d],act2[a][b][c][d])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b11dca20-77d5-4da9-ab99-fef4727eb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_layer_conv3 = qmodel.Conv2d3(fix_act1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca4a895b-f115-45fd-85ba-7ec6dda741e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(layer_conv3,qmodel_layer_conv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b08aaf-1fa8-4574-8509-b789b65b4ac6",
   "metadata": {},
   "source": [
    "### flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "18349f05-8300-4b57-8fb3-293961ff2433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 120, 1, 1])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_act2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "68fb10b1-c0b0-40c1-93ee-1781043285e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_act3 = fix_act2.view(16,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "812c4219-38d3-4708-a3c4-f966da5315ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 120])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_act3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "688241de-a700-4df3-bbdb-9986bb966d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different value is : 47/1920\n"
     ]
    }
   ],
   "source": [
    "fix_act3 = torch.zeros(16,120)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(120) :\n",
    "                fix_act3[a][b] = flp2fix(layer_act3[a][b],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act3[a][b],act3[a][b])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc809152-ee31-4a8c-8ed4-76150a013c56",
   "metadata": {},
   "source": [
    "### fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "584f3423-7ca8-4876-9233-04284997f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = torch.matmul(fix_act3,linear_filter1.t()) + linear_bias1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ef808856-eec6-42a8-9853-0873238fb0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 84])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ca4674ea-37a2-4db8-ae63-eceb89df0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc_tanh1 = tanh_2D(layer_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "82461d60-1342-4d06-a1b1-1942ca87df39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different value is : 63/1344\n"
     ]
    }
   ],
   "source": [
    "fix_act4 = torch.zeros(16,84)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(84) :\n",
    "                fix_act4[a][b] = flp2fix(layer_fc_tanh1[a][b],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act4[a][b],act4[a][b])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec1fe4-1693-474c-90de-60d00b6c8012",
   "metadata": {},
   "source": [
    "### fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "82dd086f-5d62-495a-800f-45aaf183295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc2 = torch.matmul(fix_act4,linear_filter2.t()) + linear_bias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a4ccc08d-0b74-42e8-acfb-1d5fceb4addd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a8800087-6b14-49c7-82b4-86033c1ef1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different value is : 78/160\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fix_act5 = torch.zeros(16,10)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(10) :\n",
    "                fix_act5[a][b] = flp2fix(layer_fc2[a][b],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act5[a][b],act5[a][b])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
