{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae42e62d-52d5-41e3-bb1a-0c7ba65c3ab7",
   "metadata": {},
   "source": [
    "# Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114df7ea-c3fa-47d7-bafc-9fe76df81d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd87a4ee-34c6-40c8-be95-b0bfa5f56e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from torchsummary import summary\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tq\n",
    "import os, time, math, copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_printoptions(precision=8, linewidth=50000)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936610fc-b826-4105-b8f5-aca27e1f55cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Print Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c80e2d-6adf-4fee-832d-ca9be8808d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK\t= '\\033[30m'\n",
    "RED\t\t= '\\033[31m'\n",
    "GREEN\t= '\\033[32m'\n",
    "YELLOW\t= '\\033[33m'\n",
    "BLUE\t= '\\033[34m'\n",
    "MAGENTA\t= '\\033[35m'\n",
    "CYAN\t= '\\033[36m'\n",
    "RESET\t= '\\033[0m'\n",
    "SEL\t\t= '\\033[7m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a90c48-d63c-459e-85aa-69acfe5beff7",
   "metadata": {},
   "source": [
    "# Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07042d8d-61a1-4895-b51c-ef1a9584334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class\tfxp:\n",
    "\tdef\t__init__(self, bIn, iBWF):\n",
    "\t\tself.iFullBW\t= len(bIn)\n",
    "\t\tself.iIntgBW\t= self.iFullBW - iBWF\n",
    "\t\tself.bSign\t\t= bIn[0]\n",
    "\t\tself.bIntg\t\t= bIn[:self.iIntgBW]\n",
    "\t\tself.bFrac\t\t= bIn[self.iIntgBW:]\n",
    "\t\tself.fFull\t\t= 0\n",
    "\t\ttry:\n",
    "\t\t\tfor idx, bit in enumerate(bIn):\n",
    "\t\t\t\tif\tidx == 0:\n",
    "\t\t\t\t\tself.fFull = self.fFull + int(bit,2) * -pow(2, self.iIntgBW - 1)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.fFull = self.fFull + int(bit,2) * pow(2, self.iIntgBW - 1 - idx)\n",
    "\t\texcept:\n",
    "\t\t\tprint(bIn)\n",
    "\t\tself.dispFull\t= RED + self.bIntg + BLUE + self.bFrac + RESET\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a5be79-0b57-4d5d-9229-dcfe6900e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class\tflp2fix:\n",
    "\tdef\t__init__(self, fIn, iBW, iBWF):\n",
    "\t\tself.fMin\t\t= - 2 ** (iBW - iBWF - 1)\n",
    "\t\tself.fMax\t\t= (2 ** (iBW-1) - 1) * (2 ** -iBWF)\n",
    "\t\tself.fResol\t\t= 2 ** -iBWF\n",
    "\t\tif fIn < self.fMin or fIn > self.fMax:\n",
    "\t\t\tprint(f'({fIn}): Out of input range ({self.fMax}/{self.fMin}) during flp -> fix converting ')\n",
    "\t\tself.iBW\t\t= iBW\n",
    "\t\tself.iBWI\t\t= iBW - iBWF\n",
    "\t\tself.iBWF\t\t= iBWF\n",
    "\n",
    "\t\tself.iFLP2INT\t= abs(int(fIn * 2 ** iBWF))\n",
    "\t\tif fIn < 0:\n",
    "\t\t\tself.iFLP2INT = 2 ** (iBW-1) - self.iFLP2INT\n",
    "\n",
    "\t\tif fIn >= 0:\n",
    "\t\t\tself.bFull = bin(self.iFLP2INT)[2:].rjust(iBW, '0')\n",
    "\t\telse:\n",
    "\t\t\tself.bFull = '1'+bin(self.iFLP2INT)[2:].rjust(iBW-1, '0')\n",
    "\t\t\tif len(self.bFull) > iBW:\n",
    "\t\t\t\tself.bFull = '0' * iBW\n",
    "\n",
    "\t\tself.cssFxp\t\t= fxp(self.bFull, self.iBWF)\n",
    "\t\tself.bSign\t\t= self.cssFxp.bSign\n",
    "\t\tself.bIntg\t\t= self.cssFxp.bIntg\n",
    "\t\tself.bFrac\t\t= self.cssFxp.bFrac\n",
    "\t\tself.fFull\t\t= self.cssFxp.fFull\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75346b45-fad2-4643-a086-9f79c75048ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def\tflp2fixTensor(fIn, iBW, iBWF):\n",
    "\tfMin = - 2 ** (iBW - iBWF - 1)\n",
    "\tfMax = (2 ** (iBW-1) - 1) * (2 ** -iBWF)\n",
    "\tfList = []\n",
    "\tfor aTensor in fIn.view(-1):\n",
    "\t\tfList.append(flp2fix(aTensor, iBW, iBWF).fFull)\n",
    "\treturn torch.tensor(fList).view(fIn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fd276c-3039-4782-b9cc-3a025e5f2e08",
   "metadata": {},
   "source": [
    "# User Define Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "550c26cd-69ef-492b-9516-3631b6507c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '~/dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81da7c0-fc83-4be2-8e6d-44c0c034bc40",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644a1959-2599-463e-990f-c4266e73ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch for MNIST dataset')\n",
    "parser.add_argument('--device', type=str, default='cpu', help='Device')\n",
    "parser.add_argument('--shuffle', action='store_true', default=False, help='enables data shuffle')\n",
    "parser.add_argument('--dataset', type=str, default='mnist', help='training dataset')\n",
    "parser.add_argument('--data_path', type=str, default=data_path, help='path to MNIST')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=10, help='number of epochs to train')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='optimizer')\n",
    "parser.add_argument('--loss_func', type=str, default='cel', help='optimizer')\n",
    "parser.add_argument('--quant_opt', type=str, default='asym', help='Type of Quantization')\n",
    "parser.add_argument('--full_bits', type=int, default=8, help='Number of Quantization Bits')\n",
    "parser.add_argument('--frac_bits', type=int, default=3, help='Number of Quantization Bits')\n",
    "parser.add_argument('--pretrained', type=bool, default=True, help='Pretrained Model')\n",
    "parser.add_argument('--act_quant', type=bool, default=False, help='Activation Quantization')\n",
    "parser.add_argument('--disp', type=bool, default=False, help='Display Model Information')\n",
    "\n",
    "args = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38083626-e399-49d1-8528-7ad07d2f57e5",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d593f93-d5ae-42f8-931e-4b6ab0889bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.device == 'cuda' else {}\n",
    "transforms = transforms.Compose([transforms.Resize((32,32)),transforms.ToTensor()])\n",
    "if args.dataset == 'mnist':\n",
    "\ttrain_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset=datasets.MNIST(\n",
    "\t\t\troot=args.data_path,\n",
    "\t\t\ttrain=True,\n",
    "\t\t\tdownload=True,\n",
    "\t\t\ttransform=transforms\n",
    "\t\t),\n",
    "\t\tbatch_size=args.batch_size,\n",
    "\t\tshuffle=args.shuffle,\n",
    "\t\t**kwargs\n",
    "\t)\n",
    "\n",
    "\ttest_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset=datasets.MNIST(\n",
    "\t\t\troot=args.data_path,\n",
    "\t\t\ttrain=False,\n",
    "\t\t\tdownload=True,\n",
    "\t\t\ttransform=transforms\n",
    "\t\t),\n",
    "\t\tbatch_size=args.batch_size,\n",
    "\t\tshuffle=args.shuffle,\n",
    "\t\t**kwargs\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac15596-d02e-4dfa-aed6-12d0af91c487",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee464dbd-aac4-4d82-8787-270f8cd3ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenet5(nn.Module):\n",
    "    def __init__(self): #layer sequential define\n",
    "        super(Lenet5, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5*5 square convolution\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.Conv2d1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5, stride = 1)\n",
    "        self.Conv2d2 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = 5, stride = 1)\n",
    "        self.Conv2d3 = nn.Conv2d(in_channels = 16, out_channels = 120, kernel_size = 5, stride = 1)\n",
    "        self.AvgPool2d = nn.AvgPool2d(kernel_size = 2)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.Linear1 = nn.Linear(120, 84)\n",
    "        self.Linear2 = nn.Linear(84, 10)\n",
    "    def forward(self, x) :\n",
    "        x = self.Conv2d1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.AvgPool2d(x)\n",
    "        x = self.Conv2d2(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.AvgPool2d(x)\n",
    "        x = self.Conv2d3(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.Linear1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.Linear2(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87b94f73-bd08-4b09-937c-b0788fba1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genOptimizer(model, args):\n",
    "\tif args.optimizer == 'sgd':\n",
    "\t\toptimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "\tif args.optimizer == 'adam':\n",
    "\t\toptimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\treturn optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24f3af82-03a9-4268-a864-87e3afaee89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genLossFunc(args):\n",
    "\tif args.loss_func == 'cel':\n",
    "\t\tloss_func = nn.CrossEntropyLoss()\n",
    "\treturn loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fb2e20e-9352-4066-8127-1a4118f076d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, epoch, args):\n",
    "    model.train()\n",
    "    loss_func = genLossFunc(args)\n",
    "    optimizer = genOptimizer(model, args)\n",
    "    max_batch_index = int(np.floor(len(train_loader.dataset)/args.batch_size)) #batch 번호 ..?\n",
    "    running_loss,correct = 0, 0\n",
    "    \n",
    "    for batch_index, (image, label) in enumerate(tq(train_loader, desc='Train', leave=False)):\n",
    "        image, label = image.to(args.device), label.to(args.device)\n",
    "        pred = model(image) #pred = model\n",
    "        loss = loss_func(pred, label) # model 이용해서 loss 구함)\n",
    "        running_loss += loss.item()#*image.size(0)\n",
    "        correct += (pred.argmax(1) == label).type(torch.int).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    final_loss = running_loss/len(train_loader.dataset)\n",
    "    correct_rate = 100 * correct / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1:<3d}: Avg. Loss: {final_loss:.4f}', end = '\\t')\n",
    "    print(f'Accuracy: {correct}/{len(train_loader.dataset)} ({correct_rate:>.1f}%)')\n",
    "    \n",
    "    return final_loss,correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd446a25-819f-4b37-989d-50a0353f6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, args):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_func = genLossFunc(args)\n",
    "        loss, correct = 0, 0\n",
    "# for batch_index, (image, label) in enumerate(tq(test_loader, desc='Test', leave=False)):\n",
    "        for batch_index, (image, label) in enumerate(test_loader):\n",
    "            image, label = image.to(args.device), label.to(args.device)\n",
    "            pred = model(image)\n",
    "            loss += loss_func(pred, label).item()#*image.size(0)\n",
    "            correct += (pred.argmax(1) == label).type(torch.int).sum().item()\n",
    "    loss /= len(test_loader.dataset)\n",
    "    correct_rate = 100 * correct / len(test_loader.dataset)\n",
    "    print(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%)')\n",
    "    return loss,correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c653a9bd-781a-47a9-bdcd-32f43bd1f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model):\n",
    "    train_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    eval_loss_hist = []\n",
    "    eval_acc_hist = []\n",
    "    for epoch in range(args.epochs):\n",
    "        train_loss,train_acc = train(train_loader, model, epoch, args)\n",
    "        eval_loss,eval_acc = test(test_loader, model, args)\n",
    "        train_loss_hist.append(train_loss)\n",
    "        eval_loss_hist.append(eval_loss)\n",
    "        train_acc_hist.append(train_acc)\n",
    "        eval_acc_hist.append(eval_acc)\n",
    "    print(\"Done!\")\n",
    "    return model,train_loss_hist,train_acc_hist,eval_loss_hist,eval_acc_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "485b1021-2707-4973-9c61-2a0273e71051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  : Avg. Loss: 0.0055\tAccuracy: 53471/60000 (89.1%)\n",
      "Accuracy: 9538/10000 (95.4%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2  : Avg. Loss: 0.0015\tAccuracy: 58238/60000 (97.1%)\n",
      "Accuracy: 9789/10000 (97.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3  : Avg. Loss: 0.0010\tAccuracy: 58816/60000 (98.0%)\n",
      "Accuracy: 9855/10000 (98.5%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4  : Avg. Loss: 0.0007\tAccuracy: 59134/60000 (98.6%)\n",
      "Accuracy: 9869/10000 (98.7%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5  : Avg. Loss: 0.0006\tAccuracy: 59358/60000 (98.9%)\n",
      "Accuracy: 9850/10000 (98.5%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6  : Avg. Loss: 0.0004\tAccuracy: 59482/60000 (99.1%)\n",
      "Accuracy: 9849/10000 (98.5%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7  : Avg. Loss: 0.0004\tAccuracy: 59569/60000 (99.3%)\n",
      "Accuracy: 9868/10000 (98.7%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8  : Avg. Loss: 0.0003\tAccuracy: 59636/60000 (99.4%)\n",
      "Accuracy: 9871/10000 (98.7%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9  : Avg. Loss: 0.0003\tAccuracy: 59666/60000 (99.4%)\n",
      "Accuracy: 9855/10000 (98.5%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : Avg. Loss: 0.0002\tAccuracy: 59716/60000 (99.5%)\n",
      "Accuracy: 9869/10000 (98.7%)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model,train_loss_hist,train_acc_hist,eval_loss_hist,eval_acc_hist = main(Lenet5().to(args.device))\n",
    "torch.save(model.state_dict(), 'PTQ.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "350ed278-1280-4b87-9c3e-df22702ae861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenet5(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (Conv2d1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (Conv2d2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (Conv2d3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (AvgPool2d): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (ReLU): ReLU()\n",
      "  (Linear1): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (Linear2): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26f59dbb-5579-4196-bc32-c579a258bdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "              ReLU-2            [-1, 6, 28, 28]               0\n",
      "         AvgPool2d-3            [-1, 6, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
      "              ReLU-5           [-1, 16, 10, 10]               0\n",
      "         AvgPool2d-6             [-1, 16, 5, 5]               0\n",
      "            Conv2d-7            [-1, 120, 1, 1]          48,120\n",
      "              ReLU-8            [-1, 120, 1, 1]               0\n",
      "            Linear-9                   [-1, 84]          10,164\n",
      "             ReLU-10                   [-1, 84]               0\n",
      "           Linear-11                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_size=(1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a012bf2a-6e27-4f18-9060-e95acc65299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2fix(model, args):\n",
    "\tfor name, _ in model.named_parameters():\n",
    "\t\texec(f'model.{name}.data = flp2fixTensor(model.{name}.data, {args.full_bits}, {args.frac_bits})')\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b2381db-f666-42a7-a1c5-14783fd70c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantFixForward(model, x, args):\n",
    "    cmodel = copy.deepcopy(model).to(args.device)\n",
    "    with torch.no_grad():\n",
    "        x = flp2fixTensor(x,args.full_bits,args.frac_bits)\n",
    "        \n",
    "        cnv0 = cmodel.Conv2d1(x)\n",
    "        cnv0 = flp2fixTensor(cnv0,args.full_bits,args.frac_bits)\n",
    "        \n",
    "        act0 = cmodel.ReLU(cnv0)\n",
    "        act0 = flp2fixTensor(act0, args.full_bits,args.frac_bits)\n",
    "        \n",
    "        avg0 = cmodel.AvgPool2d(act0) #activation\n",
    "        avg0 = flp2fixTensor(avg0, args.full_bits, args.frac_bits)\n",
    "\n",
    "        cnv1 = cmodel.Conv2d2(avg0)\n",
    "        cnv1 = flp2fixTensor(cnv1, args.full_bits, args.frac_bits)\n",
    "        \n",
    "        act1 = cmodel.ReLU(cnv1)\n",
    "        act1 = flp2fixTensor(act1, args.full_bits, args.frac_bits)\n",
    "        \n",
    "        avg1 = cmodel.AvgPool2d(act1)\n",
    "        avg1 = flp2fixTensor(avg1, args.full_bits, args.frac_bits)\n",
    "        \n",
    "        cnv2 = cmodel.Conv2d3(avg1)\n",
    "        cnv2 = flp2fixTensor(cnv2,args.full_bits,args.frac_bits)\n",
    "        \n",
    "        act2 = cmodel.ReLU(cnv2)\n",
    "        act2 = flp2fixTensor(act2, args.full_bits, args.frac_bits)\n",
    "            \n",
    "        flat = cmodel.flatten(act2)\n",
    "        flat = flp2fixTensor(flat,args.full_bits, args.frac_bits)\n",
    "        \n",
    "        fc1  = cmodel.Linear1(flat)\n",
    "        fc1  = flp2fixTensor(fc1, args.full_bits, args.frac_bits)\n",
    "        \n",
    "        act3 = cmodel.ReLU(fc1)\n",
    "        act3 = flp2fixTensor(act3,args.full_bits, args.frac_bits)\n",
    "        \n",
    "        fc2  = cmodel.Linear2(act3)\n",
    "        fc2  = flp2fixTensor(fc2, args.full_bits, args.frac_bits)\n",
    "        \n",
    "        act4 = cmodel.ReLU(fc2)\n",
    "        act4 = flp2fixTensor(fc2, args.full_bits, args.frac_bits)\n",
    "\n",
    "    return cmodel, cnv0, act0, avg0, cnv1, act1, avg1, cnv2, act2, flat, fc1, act3, fc2, act4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6ce915d-0d0f-47b9-9773-8083124152d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQuant(model, test_loader,args):\n",
    "    qmodel = copy.deepcopy(model).to(args.device)\n",
    "    qmodel = model2fix(qmodel, args)\n",
    "    qmodel.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_func = genLossFunc(args)\n",
    "        loss, correct = 0, 0\n",
    "        for batch_index, (image, label) in enumerate(tq(test_loader,desc='Train', leave=False)):\n",
    "            image, label = image.to(args.device), label.to(args.device)\n",
    "            qmodel, cnv0, act0, avg0, cnv1, act1, avg1, cnv2, act2, flat, fc1, act3, fc2, act4  = quantFixForward(qmodel, image, args)\n",
    "            y = act4\n",
    "            loss += loss_func(y, label).item()#*image.size(0)\n",
    "            correct += (y.argmax(1) == label).type(torch.int).sum().item()\n",
    "    correct_rate = 100 * correct / len(test_loader.dataset)\n",
    "    print(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%) Loss: {loss/len(test_loader.dataset):.2f}')\n",
    "    return qmodel, cnv0, act0, avg0, cnv1, act1, avg1, cnv2, act2, flat, fc1, act3, fc2, act4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52290d52-8e05-4362-a162-64e63799035c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8571/10000 (85.7%) Loss: 0.02\n"
     ]
    }
   ],
   "source": [
    "qmodel, cnv0, act0, avg0, cnv1, act1, avg1, cnv2, act2, flat, fc1, act3, fc2, act4= testQuant(model,test_loader,args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e6f74-e29b-4d97-a701-ea6e289a4aa1",
   "metadata": {},
   "source": [
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b1c2491-3a6f-44ad-a6a9-7e37014969d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"eval-loss\")\n",
    "\n",
    "plt.plot(range(1,args.epochs+1),train_loss_hist,label=\"train\")\n",
    "plt.plot(range(1,args.epochs+1),eval_loss_hist,label=\"eval\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15f25f03-f4eb-4806-8379-a746aa340653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.plot(range(1,args.epochs+1),train_acc_hist,label=\"train\")\n",
    "plt.plot(range(1,args.epochs+1),eval_acc_hist,label=\"eval\")\n",
    "plt.ylabel(\"accruacy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf5f840-ff00-4e01-9271-45d1acb0658d",
   "metadata": {},
   "source": [
    "# Find max, min value value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56acdfc9-07b4-464a-a467-15f19a6dbefe",
   "metadata": {},
   "source": [
    "### max, min value of input of conv layer 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0b68be01-a49a-4270-ba9e-2147a8bf56c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In input X, max value is 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f' In input X, max value is {torch.max(flp2fixTensor(a_input,args.full_bits,args.frac_bits))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaa0362-8878-493a-b314-af663d23a1db",
   "metadata": {},
   "source": [
    "### max, min value of output of conv layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "998db2f3-a0c8-49b3-9475-5200677950e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cnv layer 0, max value is 2.0, min value is -3.375\n"
     ]
    }
   ],
   "source": [
    "print(f'In cnv layer 0, max value is {torch.max(cnv0)}, min value is {torch.min(cnv0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9749051d-498c-472e-8fd8-7eab3e31c3b6",
   "metadata": {},
   "source": [
    "### max, min value ot input ouf conv layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b2a0bdbd-dc14-4aa9-953f-62083d46644a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In avg layer 0, max value is 1.875, min value is 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f'In avg layer 0, max value is {torch.max(avg0)}, min value is {torch.min(avg0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a074468-a47e-465f-9c80-478d120e12fc",
   "metadata": {},
   "source": [
    "### max, min value of output of conv layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6c55a4dd-85eb-47e7-b613-99f43440a918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cnv layer 1, max value is 3.375, min value is -6.375\n"
     ]
    }
   ],
   "source": [
    "print(f'In cnv layer 1, max value is {torch.max(cnv1)}, min value is {torch.min(cnv1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40c55e-ed5a-4131-9f8f-d931b51773d4",
   "metadata": {},
   "source": [
    "### max, min value of input of conv layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b823b87a-cc05-4fa1-bf09-8a00992616df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In avg layer 1, max value is 2.5, min value is 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f'In avg layer 1, max value is {torch.max(avg1)}, min value is {torch.min(avg1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab8632-d43b-4611-8b30-a13076a22978",
   "metadata": {},
   "source": [
    "### max, min value of output of conv layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "45d12bac-aa43-4d1e-8f88-ca267b9e7741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cnv layer 2, max value is 1.5, min value is -2.75\n"
     ]
    }
   ],
   "source": [
    "print(f'In cnv layer 2, max value is {torch.max(cnv2)}, min value is {torch.min(cnv2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0fa2c9-4630-4735-a388-f455d304abb3",
   "metadata": {},
   "source": [
    "# GenVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e61c86f3-ff4c-4912-8685-a439bbe33a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractParams(model, args):\n",
    "    for key in model.state_dict().keys():\n",
    "        layer_name = key.split('.')[0]\n",
    "        param_type = 'w' if 'weight' in key else 'b'\n",
    "        for idx, params in enumerate(eval(f'qmodel.{key}.data')):\n",
    "            with open(f'mif/{layer_name}_{param_type}_{idx}.mif', 'w') as fh:\n",
    "                if param_type == 'w':\n",
    "                    if params.dim() == 1 :\n",
    "                        #print(f'param dim is {params.dim()}')\n",
    "                        for idx, param in enumerate(params):\n",
    "                            bin_param = flp2fix(param, args.full_bits, args.frac_bits).bFull\n",
    "                            fh.write(bin_param + ('\\n','')[idx == len(params)-1])\n",
    "                    elif params.dim() == 3 :\n",
    "                        #print(f'param dim is {params.dim()}')\n",
    "                        for idx, dim1 in enumerate(params):\n",
    "                            for idx, dim2 in enumerate(dim1):\n",
    "                                for idx, param in enumerate(dim2) :\n",
    "                                    bin_param = flp2fix(param, args.full_bits, args.frac_bits).bFull\n",
    "                                    fh.write(bin_param + ('\\n','')[idx == len(params)-1])\n",
    "                else:\n",
    "                    bin_param = flp2fix(params, args.full_bits, args.frac_bits).bFull\n",
    "                    fh.write(bin_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c8a31dc-7015-4e44-9cd8-be2fd624a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genInputVector(test_loader, args):\n",
    "    out_path = './vec'\n",
    "    os.system(f'rm -rf {out_path};mkdir -p {out_path}')\n",
    "    with open(f'{out_path}/labels.vec', 'w') as fh_labels:\n",
    "        with open(f'{out_path}/images.vec', 'w') as fh_images:\n",
    "            for batch_index, (images, labels) in enumerate(test_loader):\n",
    "                for (image, label) in zip(images, labels):\n",
    "                    bin_label = flp2fix(label, args.full_bits, 0).bFull\n",
    "                    fh_labels.write(bin_label+'\\n')\n",
    "                    for pixel in image.view(-1):\n",
    "                        bin_pixel = flp2fix(pixel, args.full_bits, args.frac_bits).bFull\n",
    "                        fh_images.write(bin_pixel+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ef70461-d364-4a85-92cd-0c39f0675132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not args.pretrained:\n",
    "#extractParams(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d9791cf-47df-42eb-bcfd-f1e235598ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genInputVector(test_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fede9d53-d71e-47dd-9440-c62d6c83b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(\troot=args.data_path,\n",
    "\t\t\t\t\t\t\ttrain=False,\n",
    "\t\t\t\t\t\t\tdownload=True,\n",
    "\t\t\t\t\t\t\ttransform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "607e2d07-f8ca-4820-b046-3781c9062383",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_index, (image, label) in enumerate(test_loader):\n",
    "           image, label = image.to(args.device), label.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87d71b4b-f97e-44af-b8cb-051ec5b1ee81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99e545a3-584f-4dc7-b297-fbcbaa6641d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 32, 32])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b1dbbf8-f3fc-4da4-83bc-86f7543101be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fe6e19a-2b4c-4cac-8ea9-763de12e85d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 32, 32])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_input = image\n",
    "a_input.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee43b4ec-c7af-48cf-8d1c-4c03a14f0949",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afdc0c-7bb9-42f4-a23b-e0faf6cce086",
   "metadata": {},
   "source": [
    "### conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4569ce2a-873f-4c72-af87-509498c7c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(X, filters,bias, stride=1, pad=0):\n",
    "    n, c, h, w = X.shape # 1, 1, 32, 32\n",
    "    n_f, _, filter_h, filter_w = filters.shape\n",
    "    \n",
    "    out_h = (h+2*pad-filter_h)//stride + 1\n",
    "    out_w = (w+2*pad-filter_w)//stride + 1\n",
    "    # add padding to height and width.\n",
    "    in_X = F.pad(X,(0,0,0,0,pad,pad,pad,pad),\"constant\", 0)\n",
    "    out  = torch.zeros((n, n_f, out_h, out_w))\n",
    "    \n",
    "    for i in range(n): # for each image.\n",
    "        for c in range(n_f): # for each channel.\n",
    "            for h in range(out_h): # slide the filter vertically.\n",
    "                h_start = h * stride\n",
    "                h_end = h_start + filter_h\n",
    "                for w in range(out_w): # slide the filter horizontally.\n",
    "                    w_start = w * stride\n",
    "                    w_end = w_start + filter_w\n",
    "                    # Element-wise multiplication.\n",
    "                    out[i, c, h, w] = torch.sum(in_X[i,:,h_start:h_end,w_start:w_end]*filters[c])+bias[c]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d097de5-3122-4451-a29e-9ecd2b8e30eb",
   "metadata": {},
   "source": [
    "### ReLU_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ee8d591-bbf5-4fcf-b206-bb8308e84983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_4D(X):\n",
    "    n, c, h, w = X.shape\n",
    "    \n",
    "    out = torch.zeros(n,c,h,w)\n",
    "    \n",
    "    for i in range(n): #for each image\n",
    "        for ch in range(c) : #for each channel\n",
    "            for o_h in range(h) : #for each height\n",
    "                for o_w in range(w) : #for each width\n",
    "                    x = X[i, ch, o_h, o_w]\n",
    "                    if x > 0 :\n",
    "                        out[i, ch, o_h, o_w] = x\n",
    "                    else :\n",
    "                        out[i, ch, o_h, o_w] = 0\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634285a-385c-4adc-b16d-48390b197cfd",
   "metadata": {},
   "source": [
    "### ReLU_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fef2a00e-c5ad-426d-b421-dbb892fec801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_2D(X):\n",
    "    n, c = X.shape\n",
    "    \n",
    "    out = torch.zeros(n,c)\n",
    "    \n",
    "    for i in range(n): #for each image\n",
    "        for ch in range(c) : #for each channel\n",
    "                    x = X[i, ch]\n",
    "                    if x > 0 :\n",
    "                        out[i, ch ] = x\n",
    "                    else :\n",
    "                        out[i, ch ] = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b514de-2220-4e48-8c38-7eee5d2eba6f",
   "metadata": {},
   "source": [
    "### avgpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a4628c8-42b1-4dcb-838d-20ed940f4307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avgpool2d(X,kernel_size,stride,pad=0):\n",
    "    n, c, h, w = X.shape\n",
    "    ker_w, ker_h = kernel_size\n",
    "    \n",
    "    out_h = (h + 2*pad - ker_h)//stride + 1\n",
    "    out_w = (w + 2*pad - ker_w)//stride + 1\n",
    "    \n",
    "    out = torch.zeros(n,c,out_h,out_w)\n",
    "    for i in range(n) : #for each image\n",
    "        for ch in range(c) : #for each channel \n",
    "             for h in range(out_h) :\n",
    "                    h_start = h * stride\n",
    "                    h_end = h_start + ker_w\n",
    "                    for w in range(out_w):\n",
    "                        w_start = w * stride\n",
    "                        w_end = w_start + ker_w\n",
    "                        #element average\n",
    "                        out[i, ch, h, w] = torch.mean(X[i,ch,h_start:h_end,w_start:w_end])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f5e21-3675-4a78-9f94-4fbf4e1013a3",
   "metadata": {},
   "source": [
    "### linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f176c-8735-4dcb-a763-6e685d280851",
   "metadata": {},
   "source": [
    "## checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fa2d71b-b6d4-466e-b840-a598f7a57742",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters1 = qmodel.Conv2d1.weight\n",
    "filters2 = qmodel.Conv2d2.weight\n",
    "filters3 = qmodel.Conv2d3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ecbe49f-47f5-44d8-a408-df727d92c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias1 = qmodel.Conv2d1.bias\n",
    "bias2 = qmodel.Conv2d2.bias\n",
    "bias3 = qmodel.Conv2d3.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84792791-321a-4fc9-931e-59a8d156c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_filter1 = qmodel.Linear1.weight\n",
    "linear_filter2 = qmodel.Linear2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f048caa-5905-4324-9d06-f8056b5806c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_bias1 = qmodel.Linear1.bias\n",
    "linear_bias2 = qmodel.Linear2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea6a0c8e-c3a2-430a-8311-d18c1877101c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84, 120])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_filter1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87dd94e7-f94e-4821-b7e7-a54144b5161b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 84])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_filter2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e07e1-d32a-49cf-9c7d-a65d4e66c61e",
   "metadata": {},
   "source": [
    "### act0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bd151a5c-362d-4b25-8af9-0fe4d1ec9db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1 = conv(flp2fixTensor(a_input,args.full_bits,args.frac_bits),filters1,bias1,stride=1,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ceb262ca-a1f5-4539-b0dc-e5362b34b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ReLU1 = ReLU_4D(layer_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5aca4a62-febd-4d03-b1d3-2c6db27fc94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_avgpool1 = avgpool2d(layer_ReLU1,(2,2),2,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c9274cd8-39f2-46e4-bb16-0d8abc208992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 14, 14])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_avgpool1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "84b4e9e4-b3ed-42b3-8775-bfd6cadbcc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 28, 28])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fa6f87ac-43ba-48e0-8e76-077b7743b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different value is : 0/75264\n"
     ]
    }
   ],
   "source": [
    "fix_cnv0 = torch.zeros(16,6,28,28)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(6) :\n",
    "        for c in range(28) :\n",
    "            for d in range(28) :\n",
    "                fix_cnv0[a][b][c][d] = flp2fix(layer_conv1[a][b][c][d],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_cnv0[a][b][c][d],cnv0[a][b][c][d])==False):\n",
    "                    num += 1\n",
    "                #bin_conv1[a][b][c][d] = flp2fix(fix_conv1[a][b][c][d],args.full_bits,args.frac_bits).bFull\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b48be63e-b475-43a3-96c8-1b47ab42a723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(fix_cnv0,cnv0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19a199-0b9a-488d-8b00-97e49ed5729f",
   "metadata": {},
   "source": [
    "### act1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b97ec681-83b9-4585-a937-862ae90a6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv2 = conv(fix_act0,filters2,bias2,stride=1,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a707f846-356f-4d1d-82b2-65b877373350",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ReLU2 = ReLU_4D(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "caeaa0b5-8da9-44dc-a72d-fdd40a2176e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_avgpool2 = avgpool2d(layer_ReLU2,(2,2),2,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ca2fdbc4-b15c-4002-8175-0a8693ee5857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 5, 5])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_avgpool2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "542f6201-c8c4-44ea-be0a-ab52be8a1e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 10, 10])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41996925-65cc-4bf8-93ce-f08c57b3ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_act1 = torch.zeros(16,16,5,5)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(16) :\n",
    "        for c in range(5) :\n",
    "            for d in range(5) :\n",
    "                fix_act1[a][b][c][d] = flp2fix(layer_avgpool2[a][b][c][d],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act1[a][b][c][d],act1[a][b][c][d])==False):\n",
    "                    num += 1\n",
    "                    print(fix_act1[a][b][c][d].item())\n",
    "                    print(act1[a][b][c][d].item())\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb65f3d-5088-4223-816f-9da415725f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(fix_act1,act1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3cd71-8a41-49ba-846b-d1755d7cabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_layer_conv2 = qmodel.Conv2d2(fix_act0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef531d-5010-42d8-b370-574977814e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(layer_conv2,qmodel_layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b037533d-31a6-444a-9523-135d9709b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_layer_ReLU2 = qmodel.ReLU(qmodel_layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df75c8-ba80-44fa-bffd-b513ab78ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(layer_ReLU2,qmodel_layer_ReLU2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc7bd2c-c64b-45b1-af66-12583c1d742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(16) :\n",
    "        for c in range(10) :\n",
    "            for d in range(10) :\n",
    "                if (torch.equal(layer_ReLU2[a][b][c][d],qmodel_layer_ReLU2[a][b][c][d])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa28b7-1dd1-4c5b-91af-a54f2e9ffbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_layer_avgpool2 = qmodel.AvgPool2d(qmodel_layer_ReLU2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a298fd-76ea-4195-9cb3-48c9dd63245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_fix_act1 = torch.zeros(16,16,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51655bfd-fdca-4724-b088-713dd50f970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(16) :\n",
    "        for c in range(5) :\n",
    "            for d in range(5) :\n",
    "                qmodel_fix_act1[a][b][c][d] = flp2fix(qmodel_layer_avgpool2[a][b][c][d],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act1[a][b][c][d],qmodel_fix_act1[a][b][c][d])==False):\n",
    "                    num += 1                \n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad94aef8-9ecd-4cc3-996e-b03fba24bf34",
   "metadata": {},
   "source": [
    "### act2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7882e74-d68c-424b-b5d0-2e9e5533f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv3 = conv(fix_act1,filters3,bias3,stride=1,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7b56d-c09e-4235-a6bb-3e18b05e09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ReLU3 = ReLU_4D(layer_conv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f7e44-72d7-4d10-9258-28ceee56962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "act2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd8cdd0-94d1-456a-8467-2dd41cb3a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_act2 = torch.zeros(16,120,1,1)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(120) :\n",
    "        for c in range(1) :\n",
    "            for d in range(1) :\n",
    "                fix_act2[a][b][c][d] = flp2fix(layer_ReLU3[a][b][c][d],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act2[a][b][c][d],act2[a][b][c][d])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11dca20-77d5-4da9-ab99-fef4727eb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_layer_conv3 = qmodel.Conv2d3(fix_act1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a895b-f115-45fd-85ba-7ec6dda741e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(layer_conv3,qmodel_layer_conv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b08aaf-1fa8-4574-8509-b789b65b4ac6",
   "metadata": {},
   "source": [
    "### flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18349f05-8300-4b57-8fb3-293961ff2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_act2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb10b1-c0b0-40c1-93ee-1781043285e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_act3 = fix_act2.view(16,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812c4219-38d3-4708-a3c4-f966da5315ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_act3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688241de-a700-4df3-bbdb-9986bb966d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_act3 = torch.zeros(16,120)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(120) :\n",
    "                fix_act3[a][b] = flp2fix(layer_act3[a][b],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act3[a][b],act3[a][b])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc809152-ee31-4a8c-8ed4-76150a013c56",
   "metadata": {},
   "source": [
    "### fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f3423-7ca8-4876-9233-04284997f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = torch.matmul(fix_act3,linear_filter1.t()) + linear_bias1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef808856-eec6-42a8-9853-0873238fb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4674ea-37a2-4db8-ae63-eceb89df0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc_ReLU1 = ReLU_2D(layer_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82461d60-1342-4d06-a1b1-1942ca87df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_act4 = torch.zeros(16,84)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(84) :\n",
    "                fix_act4[a][b] = flp2fix(layer_fc_ReLU1[a][b],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act4[a][b],act4[a][b])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec1fe4-1693-474c-90de-60d00b6c8012",
   "metadata": {},
   "source": [
    "### fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd086f-5d62-495a-800f-45aaf183295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc2 = torch.matmul(fix_act4,linear_filter2.t()) + linear_bias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ccc08d-0b74-42e8-acfb-1d5fceb4addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8800087-6b14-49c7-82b4-86033c1ef1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fix_act5 = torch.zeros(16,10)\n",
    "\n",
    "total = 0\n",
    "num = 0\n",
    "\n",
    "for a in range(16) :\n",
    "    for b in range(10) :\n",
    "                fix_act5[a][b] = flp2fix(layer_fc2[a][b],args.full_bits,args.frac_bits).fFull\n",
    "                if (torch.equal(fix_act5[a][b],act5[a][b])==False):\n",
    "                    num += 1\n",
    "                total += 1\n",
    "\n",
    "print(\"number of different value is : {num}/{total}\".format(num=num,total=total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94693a80-c055-4eb3-9274-0ce4755cf433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece828f-4faa-4502-85e4-eb16109dcc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
